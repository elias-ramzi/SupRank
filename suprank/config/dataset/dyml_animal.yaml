hierarchy_level: 3
num_classes_train_level0: 495
num_classes_train_level1: 28
num_classes_train_level2: 5
num_samples_train:

recall_for_eval: [1]

sampler:
  _target_: ${if:${distributed},suprank.datasets.samplers.DistributedMPerClassSampler,suprank.datasets.samplers.MPerClassSampler}
  batch_size: 256
  samples_per_class: 4

dts:

  train:
    _target_: suprank.datasets.DyMLDataset
    data_dir: /local/DEEPLEARNING/image_retrieval/dyml_animal
    alpha: 1.0
    relevance_type: pop
    mode: train
    transform:
      _target_: torchvision.transforms.Compose
      transforms:
        - _target_: torchvision.transforms.RandomResizedCrop
          scale: [0.16, 1]
          ratio: [0.75, 1.33]
          size: 224
        - _target_: torchvision.transforms.RandomHorizontalFlip
          p: 0.5
        - _target_: torchvision.transforms.ToTensor
        - _target_: torchvision.transforms.Normalize
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]

  test:

    - query:
        _target_: suprank.datasets.DyMLDataset
        data_dir: ${dataset.dts.train.data_dir}
        alpha: ${dataset.dts.train.alpha}
        relevance_type: ${dataset.dts.train.relevance_type}
        mode: test_query_fine
        transform:
          _target_: torchvision.transforms.Compose
          transforms:
            - _target_: torchvision.transforms.Resize
              size: 256
            - _target_: torchvision.transforms.CenterCrop
              size: 224
            - _target_: torchvision.transforms.ToTensor
            - _target_: torchvision.transforms.Normalize
              mean: [0.485, 0.456, 0.406]
              std: [0.229, 0.224, 0.225]

      gallery_distractor:
        _target_: suprank.datasets.DyMLDataset
        data_dir: ${dataset.dts.train.data_dir}
        alpha: ${dataset.dts.train.alpha}
        relevance_type: ${dataset.dts.train.relevance_type}
        mode: test_gallery_fine
        transform:
          _target_: torchvision.transforms.Compose
          transforms:
            - _target_: torchvision.transforms.Resize
              size: 256
            - _target_: torchvision.transforms.CenterCrop
              size: 224
            - _target_: torchvision.transforms.ToTensor
            - _target_: torchvision.transforms.Normalize
              mean: [0.485, 0.456, 0.406]
              std: [0.229, 0.224, 0.225]

    - query:
        _target_: suprank.datasets.DyMLDataset
        data_dir: ${dataset.dts.train.data_dir}
        alpha: ${dataset.dts.train.alpha}
        relevance_type: ${dataset.dts.train.relevance_type}
        mode: test_query_middle
        transform:
          _target_: torchvision.transforms.Compose
          transforms:
            - _target_: torchvision.transforms.Resize
              size: 256
            - _target_: torchvision.transforms.CenterCrop
              size: 224
            - _target_: torchvision.transforms.ToTensor
            - _target_: torchvision.transforms.Normalize
              mean: [0.485, 0.456, 0.406]
              std: [0.229, 0.224, 0.225]

      gallery_distractor:
        _target_: suprank.datasets.DyMLDataset
        data_dir: ${dataset.dts.train.data_dir}
        alpha: ${dataset.dts.train.alpha}
        relevance_type: ${dataset.dts.train.relevance_type}
        mode: test_gallery_middle
        transform:
          _target_: torchvision.transforms.Compose
          transforms:
            - _target_: torchvision.transforms.Resize
              size: 256
            - _target_: torchvision.transforms.CenterCrop
              size: 224
            - _target_: torchvision.transforms.ToTensor
            - _target_: torchvision.transforms.Normalize
              mean: [0.485, 0.456, 0.406]
              std: [0.229, 0.224, 0.225]

    - query:
        _target_: suprank.datasets.DyMLDataset
        data_dir: ${dataset.dts.train.data_dir}
        alpha: ${dataset.dts.train.alpha}
        relevance_type: ${dataset.dts.train.relevance_type}
        mode: test_query_coarse
        transform:
          _target_: torchvision.transforms.Compose
          transforms:
            - _target_: torchvision.transforms.Resize
              size: 256
            - _target_: torchvision.transforms.CenterCrop
              size: 224
            - _target_: torchvision.transforms.ToTensor
            - _target_: torchvision.transforms.Normalize
              mean: [0.485, 0.456, 0.406]
              std: [0.229, 0.224, 0.225]

      gallery_distractor:
        _target_: suprank.datasets.DyMLDataset
        data_dir: ${dataset.dts.train.data_dir}
        alpha: ${dataset.dts.train.alpha}
        relevance_type: ${dataset.dts.train.relevance_type}
        mode: test_gallery_coarse
        transform:
          _target_: torchvision.transforms.Compose
          transforms:
            - _target_: torchvision.transforms.Resize
              size: 256
            - _target_: torchvision.transforms.CenterCrop
              size: 224
            - _target_: torchvision.transforms.ToTensor
            - _target_: torchvision.transforms.Normalize
              mean: [0.485, 0.456, 0.406]
              std: [0.229, 0.224, 0.225]
